{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  \n",
    "import imageio.v3 as iio \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import joblib  # For saving and loading the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set paths for images \n",
    "train_root = 'skin_disease_dataset/train_set'\n",
    "test_root = 'skin_disease_dataset/test_set'\n",
    "\n",
    "# Path to save/load the model and features\n",
    "model_filename = 'skin_disease_model.pkl'#to save the model\n",
    "train_features_filename = 'train_features.npy'#to save the tarin features\n",
    "test_features_filename = 'test_features.npy'#to save the test features\n",
    "#loading data\n",
    "def load_data(root):\n",
    "    path = []#list to store the file paths of all images \n",
    "    labels = []#list to store the labels for each image \n",
    "    for folder_name in os.listdir(root):\n",
    "        folder_path = os.path.join(root, folder_name)#construct full path \n",
    "        if os.path.isdir(folder_path):#check if the folder_path is directory\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                path.append(file_path)\n",
    "                labels.append(folder_name)  # Assuming folder name is the label\n",
    "    return pd.DataFrame({'disease path': path, 'disease name': labels})\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = load_data(train_root)\n",
    "# print(train_df)\n",
    "test_df = load_data(test_root)\n",
    "\n",
    "# --- Display the first image ---\n",
    "# if not train_df.empty:\n",
    "#     num_images = min(5, len(train_df))  # Display just 5 images\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, num_images, figsize=(15, 5))  # Create a single row of subplots\n",
    "\n",
    "#     for i in range(num_images):\n",
    "#         # Get the image path and label\n",
    "#         image_path = train_df.iloc[i]['disease path']\n",
    "#         label = train_df.iloc[i]['disease name']\n",
    "        \n",
    "#         try:\n",
    "#             # Read the image\n",
    "#             image = iio.imread(image_path)\n",
    "            \n",
    "#             # Display the image in the corresponding subplot\n",
    "#             axes[i].imshow(image)\n",
    "#             axes[i].set_title(f\"Disease: {label}\")\n",
    "#             axes[i].axis('off')  # Hide axes\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading image {image_path}: {e}\")\n",
    "#             axes[i].axis('off')  # Hide the axes even if an error occurs\n",
    "\n",
    "#     plt.tight_layout()  # Adjust the layout to prevent overlapping\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     print(\"No images found in the training dataset.\")\n",
    "#     print(\"No images found in the training dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from files, no need to extract again.\n",
      "Model loaded from file, no need to retrain.\n",
      "Accuracy: 92.31%\n",
      "Precision: 0.92\n",
      "Recall: 0.92\n",
      "F1-score: 0.92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "train_df['disease name'] = le.fit_transform(train_df['disease name'])\n",
    "test_df['disease name'] = le.transform(test_df['disease name'])\n",
    "# print(train_df['disease name'])\n",
    "\n",
    "# Prepare features and labels\n",
    "X_train = train_df['disease path']\n",
    "y_train = train_df['disease name']\n",
    "X_test = test_df['disease path'] \n",
    "y_test = test_df['disease name']\n",
    "\n",
    "def load_and_preprocess_image(filepath, size=(128, 128)):\n",
    "    try:\n",
    "        img = Image.open(filepath).convert('RGB')  # Ensure image is in RGB mode\n",
    "        img = img.resize(size)  # Resize the image\n",
    "        img = img_to_array(img) / 255.0  # Convert to array and normalize\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load pretrained CNN model for feature extraction\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "\n",
    "# Extract features from images\n",
    "def extract_features(image_paths):\n",
    "    features = []\n",
    "    for path in image_paths:\n",
    "        img = load_and_preprocess_image(path)\n",
    "        if img is not None:\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "            feature = feature_extractor.predict(img)\n",
    "            features.append(feature.flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "# Check if the feature files exist\n",
    "if os.path.exists(train_features_filename) and os.path.exists(test_features_filename):\n",
    "    # Load extracted features from files\n",
    "    X_train_features = np.load(train_features_filename)\n",
    "    X_test_features = np.load(test_features_filename)\n",
    "    print(\"Features loaded from files, no need to extract again.\")\n",
    "else:\n",
    "    # Extract features for train and test datasets\n",
    "    X_train_features = extract_features(X_train)\n",
    "    X_test_features = extract_features(X_test)\n",
    "    # Save the features to files\n",
    "    np.save(train_features_filename, X_train_features)\n",
    "    np.save(test_features_filename, X_test_features)\n",
    "    print(\"Features extracted and saved to files.\")\n",
    "\n",
    "# Check if the model file exists\n",
    "if os.path.exists(model_filename):\n",
    "    # Load the saved model\n",
    "    clf = joblib.load(model_filename)\n",
    "    print(\"Model loaded from file, no need to retrain.\")\n",
    "else:\n",
    "    # SVM Parameter Grid\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale']\n",
    "    }\n",
    "    grid_search = GridSearchCV(svm.SVC(class_weight='balanced'), param_grid, scoring='accuracy', cv=5)\n",
    "    \n",
    "    # Train the model\n",
    "    grid_search.fit(X_train_features, y_train)\n",
    "    clf = grid_search.best_estimator_\n",
    "    \n",
    "\n",
    "    # Save the model after training\n",
    "    joblib.dump(clf, model_filename) \n",
    "    print(\"Model trained and saved to file.\")\n",
    "\n",
    "# Test the model with the test set\n",
    "y_pred = clf.predict(X_test_features)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
